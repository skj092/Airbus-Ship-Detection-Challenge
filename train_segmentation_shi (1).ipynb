{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "GuHzcAhn5z6d"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# pd.options.plotting.backend = \"plotly\"\n",
    "import random\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import os, shutil\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import time\n",
    "import copy\n",
    "import joblib\n",
    "from collections import defaultdict\n",
    "import gc\n",
    "from IPython import display as ipd\n",
    "\n",
    "# visualization\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, StratifiedGroupKFold\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda import amp\n",
    "\n",
    "import timm\n",
    "\n",
    "# Albumentations for augmentations\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# import rasterio\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# For colored terminal text\n",
    "from colorama import Fore, Back, Style\n",
    "c_  = Fore.GREEN\n",
    "sr_ = Style.RESET_ALL\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# For descriptive error messages\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "2NCKiYVU5z6e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /teamspace/studios/this_studio/.netrc\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import os\n",
    "# os.environ['WANDB_API_KEY'] = api_key\n",
    "# wandb.login(key=api_key)\n",
    "\n",
    "try:\n",
    "    # from kaggle_secrets import UserSecretsClient\n",
    "    # user_secrets = UserSecretsClient()\n",
    "    # api_key = user_secrets.get_secret(\"wandb\")\n",
    "    # from google.colab import userdata\n",
    "    api_key = \"\"\n",
    "    os.environ['WANDB_API_KEY'] = api_key\n",
    "    wandb.login(key=api_key)\n",
    "    anonymous = None\n",
    "except:\n",
    "    anonymous = \"must\"\n",
    "    print('To use your W&B account,\\nGo to Add-ons -> Secrets and provide your W&B access token. Use the Label name as WANDB. \\nGet your W&B access token from here: https://wandb.ai/authorize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "QMc1zng35z6f"
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    seed          = 101\n",
    "    debug         = False # set debug=False for Full Training\n",
    "    exp_name      = 'Baselinev2'\n",
    "    comment       = 'unet-efficientnet_b1-224x224-aug2-split2'\n",
    "    model_name    = 'Unet'\n",
    "    backbone      = 'efficientnet-b1'\n",
    "    train_bs      = 128\n",
    "    valid_bs      = train_bs*2\n",
    "    img_size      = [224, 224]\n",
    "    epochs        = 15\n",
    "    lr            = 2e-3\n",
    "    scheduler     = 'CosineAnnealingLR'\n",
    "    min_lr        = 1e-6\n",
    "    T_max         = int(30000/train_bs*epochs)+50\n",
    "    T_0           = 25\n",
    "    warmup_epochs = 0\n",
    "    wd            = 1e-6\n",
    "    n_accumulate  = max(1, 32//train_bs)\n",
    "    n_fold        = 5\n",
    "    num_classes   = 1\n",
    "    device        = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "uyNPLw4R5z6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> SEEDING DONE\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed = 42):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    print('> SEEDING DONE')\n",
    "\n",
    "set_seed(CFG.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "sNbQ9Rk95z6g"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "      <th>rle_len</th>\n",
       "      <th>empty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00003e153.jpg</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001124c7.jpg</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000155de5.jpg</td>\n",
       "      <td>264661 17 265429 33 266197 33 266965 33 267733...</td>\n",
       "      <td>1038</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>360486 1 361252 4 362019 5 362785 8 363552 10 ...</td>\n",
       "      <td>213</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>51834 9 52602 9 53370 9 54138 9 54906 9 55674 ...</td>\n",
       "      <td>143</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ImageId                                      EncodedPixels  rle_len  \\\n",
       "0  00003e153.jpg                                                           0   \n",
       "1  0001124c7.jpg                                                           0   \n",
       "2  000155de5.jpg  264661 17 265429 33 266197 33 266965 33 267733...     1038   \n",
       "3  000194a2d.jpg  360486 1 361252 4 362019 5 362785 8 363552 10 ...      213   \n",
       "4  000194a2d.jpg  51834 9 52602 9 53370 9 54138 9 54906 9 55674 ...      143   \n",
       "\n",
       "   empty  \n",
       "0   True  \n",
       "1   True  \n",
       "2  False  \n",
       "3  False  \n",
       "4  False  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE_PATH  = '/teamspace/studios/this_studio/.cache/kagglehub/competitions/airbus-ship-detection'\n",
    "\n",
    "df = pd.read_csv(BASE_PATH+'/train_ship_segmentations_v2.csv')\n",
    "df['EncodedPixels'] = df.EncodedPixels.fillna('')\n",
    "df['rle_len'] = df.EncodedPixels.map(len) # length of each rle mask\n",
    "df['empty'] = (df.rle_len==0) # empty masks\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "AJ2xPF3t5z6h"
   },
   "outputs": [],
   "source": [
    "def get_mask(img_id, df):\n",
    "    shape = (768,768)\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    masks = df.loc[img_id]['EncodedPixels']\n",
    "    if(type(masks) == float): return img.reshape(shape)\n",
    "    if(type(masks) == str): masks = [masks]\n",
    "    for mask in masks:\n",
    "        s = mask.split()\n",
    "        for i in range(len(s)//2):\n",
    "            start = int(s[2*i]) - 1\n",
    "            length = int(s[2*i+1])\n",
    "            img[start:start+length] = 1\n",
    "    return img.reshape(shape).T\n",
    "\n",
    "def load_img(path):\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)  # read as BGR by default\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Image at {path} could not be loaded.\")\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # convert to RGB\n",
    "\n",
    "    img = img.astype('float32')  # convert from uint8 to float32\n",
    "    mx = np.max(img)\n",
    "    if mx:\n",
    "        img /= mx  # scale to [0, 1]\n",
    "    return img\n",
    "\n",
    "def load_msk(path):\n",
    "    msk = np.load(path)\n",
    "    msk = msk.astype('float32')\n",
    "    msk/=255.0\n",
    "    return msk\n",
    "\n",
    "\n",
    "def show_img(img, mask=None):\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "#     img = clahe.apply(img)\n",
    "#     plt.figure(figsize=(10,10))\n",
    "    plt.imshow(img, cmap='bone')\n",
    "\n",
    "    if mask is not None:\n",
    "        # plt.imshow(np.ma.masked_where(mask!=1, mask), alpha=0.5, cmap='autumn')\n",
    "        plt.imshow(mask, alpha=0.5)\n",
    "        handles = [Rectangle((0,0),1,1, color=_c) for _c in [(0.667,0.0,0.0), (0.0,0.667,0.0), (0.0,0.0,0.667)]]\n",
    "        labels = [\"ship\"]\n",
    "        plt.legend(handles,labels)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "EA2NSDKn5z6i"
   },
   "outputs": [],
   "source": [
    "# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\n",
    "def rle_decode(mask_rle, shape):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return\n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape)  # Needed to align to RLE direction\n",
    "\n",
    "\n",
    "# ref.: https://www.kaggle.com/stainsby/fast-tested-rle\n",
    "def rle_encode(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = img.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "u5VITrj95z6i"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fold  empty\n",
       "0.0   False    16345\n",
       "      True     30000\n",
       "1.0   False    16345\n",
       "      True     30000\n",
       "2.0   False    16345\n",
       "      True     30000\n",
       "3.0   False    16344\n",
       "      True     30000\n",
       "4.0   False    16344\n",
       "      True     30000\n",
       "Name: ImageId, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(df, y=df['empty'])):\n",
    "    df.loc[val_idx, 'fold'] = fold\n",
    "display(df.groupby(['fold','empty'])['ImageId'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "SlRGCrOU5z6i"
   },
   "outputs": [],
   "source": [
    "def get_mask(img_id, df):\n",
    "    df = df.set_index('ImageId')\n",
    "    shape = (768,768)\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    masks = df.loc[img_id]['EncodedPixels']\n",
    "    if(type(masks) == float): return img.reshape(shape)\n",
    "    if(type(masks) == str): masks = [masks]\n",
    "    for mask in masks:\n",
    "        s = mask.split()\n",
    "        for i in range(len(s)//2):\n",
    "            start = int(s[2*i]) - 1\n",
    "            length = int(s[2*i+1])\n",
    "            img[start:start+length] = 1\n",
    "    return img.reshape(shape).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "rU1IXRTB5z6j"
   },
   "outputs": [],
   "source": [
    "class BuildDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, transforms=None):\n",
    "        self.df         = df\n",
    "        self.ImageId  = df['ImageId'].unique().tolist()\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ImageId)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_id  = self.ImageId[index]\n",
    "        img_path = os.path.join(os.path.join(str(BASE_PATH), 'train_v2', img_id))\n",
    "        \n",
    "        img = []\n",
    "        img = load_img(img_path)\n",
    "        msk = np.load(os.path.join(\"masks_npy\", img_id+'.npy'))\n",
    "        if self.transforms:\n",
    "            data = self.transforms(image=img, mask=msk)\n",
    "            img  = data['image']\n",
    "            msk  = data['mask']\n",
    "        img = np.transpose(img, (2, 0, 1))\n",
    "        return torch.tensor(img, dtype=torch.float32), torch.tensor(msk, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(path):\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)  # read as BGR by default\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Image at {path} could not be loaded.\")\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # convert to RGB\n",
    "\n",
    "    img = img.astype('float32')  # convert from uint8 to float32\n",
    "    mx = np.max(img)\n",
    "    if mx:\n",
    "        img /= mx  # scale to [0, 1]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "1k7iWvyg5z6j"
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    \"train\": A.Compose([\n",
    "        A.Resize(*CFG.img_size, interpolation=cv2.INTER_NEAREST),\n",
    "        # A.HorizontalFlip(p=0.5),\n",
    "        # A.VerticalFlip(p=0.5),\n",
    "        # A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.05, rotate_limit=10, p=0.5),\n",
    "        # A.OneOf([\n",
    "        #     A.GridDistortion(num_steps=5, distort_limit=0.05, p=1.0),\n",
    "        #     A.OpticalDistortion(distort_limit=0.05, shift_limit=0.05, p=1.0),\n",
    "        #     A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=1.0)\n",
    "        # ], p=0.25),\n",
    "        # A.CoarseDropout(max_holes=8, max_height=CFG.img_size[0]//20, max_width=CFG.img_size[1]//20,\n",
    "        #                  min_holes=5, fill_value=0, mask_fill_value=0, p=0.5),\n",
    "        ], p=1.0),\n",
    "\n",
    "    \"valid\": A.Compose([\n",
    "        A.Resize(*CFG.img_size, interpolation=cv2.INTER_NEAREST),\n",
    "        ], p=1.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "XCNNbKXo5z6j"
   },
   "outputs": [],
   "source": [
    "def prepare_loaders(fold, debug=False):\n",
    "    train_df = df.query(\"fold!=@fold\").reset_index(drop=True)\n",
    "    valid_df = df.query(\"fold==@fold\").reset_index(drop=True)\n",
    "    if debug:\n",
    "        train_df = train_df.head(32*5).query(\"empty==0\")\n",
    "        valid_df = valid_df.head(32*3).query(\"empty==0\")\n",
    "    train_dataset = BuildDataset(train_df, transforms=data_transforms['train'])\n",
    "    valid_dataset = BuildDataset(valid_df, transforms=data_transforms['valid'])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=CFG.train_bs if not debug else 20,\n",
    "                              num_workers=4, shuffle=True, pin_memory=True, drop_last=False)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=CFG.valid_bs if not debug else 20,\n",
    "                              num_workers=4, shuffle=False, pin_memory=True)\n",
    "\n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "Q2CdqyIC5z6k"
   },
   "outputs": [],
   "source": [
    "def plot_batch(imgs, msks, size=3):\n",
    "    plt.figure(figsize=(5*5, 5))\n",
    "    for idx in range(size):\n",
    "        plt.subplot(1, 5, idx+1)\n",
    "        img = imgs[idx,].permute((1, 2, 0)).numpy()*255.0\n",
    "        img = img.astype('uint8')\n",
    "        msk = msks[idx,].numpy()*255.0\n",
    "        show_img(img, msk)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "5vdbjeKe5z6k"
   },
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "def build_model():\n",
    "    model = smp.Unet(\n",
    "        encoder_name=CFG.backbone,      # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "        encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "        in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "        classes=CFG.num_classes,        # model output channels (number of classes in your dataset)\n",
    "        activation=None,\n",
    "    )\n",
    "    model.to(CFG.device)\n",
    "    return model\n",
    "\n",
    "def load_model(path):\n",
    "    model = build_model()\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "o7Y9ejjU5z6k"
   },
   "outputs": [],
   "source": [
    "JaccardLoss = smp.losses.JaccardLoss(mode='binary')\n",
    "DiceLoss    = smp.losses.DiceLoss(mode='binary')\n",
    "BCELoss     = smp.losses.SoftBCEWithLogitsLoss()\n",
    "LovaszLoss  = smp.losses.LovaszLoss(mode='binary', per_image=False)\n",
    "TverskyLoss = smp.losses.TverskyLoss(mode='binary', log_loss=False)\n",
    "\n",
    "def dice_coef(y_true, y_pred, thr=0.5, dim=(2,3), epsilon=0.001):\n",
    "    y_true = y_true.unsqueeze(1)\n",
    "    y_true = y_true.to(torch.float32)\n",
    "    y_pred = (y_pred>thr).to(torch.float32)\n",
    "    inter = (y_true*y_pred).sum(dim=dim)\n",
    "    den = y_true.sum(dim=dim) + y_pred.sum(dim=dim)\n",
    "    dice = ((2*inter+epsilon)/(den+epsilon)).mean(dim=(1,0))\n",
    "    return dice\n",
    "\n",
    "def iou_coef(y_true, y_pred, thr=0.5, dim=(2,3), epsilon=0.001):\n",
    "    y_true = y_true.unsqueeze(1)\n",
    "    y_true = y_true.to(torch.float32)\n",
    "    y_pred = (y_pred>thr).to(torch.float32)\n",
    "    inter = (y_true*y_pred).sum(dim=dim)\n",
    "    union = (y_true + y_pred - y_true*y_pred).sum(dim=dim)\n",
    "    iou = ((inter+epsilon)/(union+epsilon)).mean(dim=(1,0))\n",
    "    return iou\n",
    "\n",
    "def criterion(y_pred, y_true):\n",
    "    y_true = y_true.unsqueeze(1)\n",
    "    return 0.5*BCELoss(y_pred, y_true) + 0.5*TverskyLoss(y_pred, y_true)\n",
    "\n",
    "def dice_per_class(y_true, y_pred, smooth=1e-6):\n",
    "    \"\"\"\n",
    "    y_true, y_pred: tensors with shape (B, 1, H, W)\n",
    "    Assumes binary mask: 0 (background), 1 (object)\n",
    "    \"\"\"\n",
    "    y_true = y_true.view(-1)\n",
    "    y_pred = y_pred.view(-1)\n",
    "\n",
    "    # Foreground mask (label == 1)\n",
    "    intersection_fg = (y_true * y_pred).sum()\n",
    "    dice_fg = (2. * intersection_fg + smooth) / (y_true.sum() + y_pred.sum() + smooth)\n",
    "\n",
    "    # Background mask (label == 0)\n",
    "    y_true_bg = 1 - y_true\n",
    "    y_pred_bg = 1 - y_pred\n",
    "    intersection_bg = (y_true_bg * y_pred_bg).sum()\n",
    "    dice_bg = (2. * intersection_bg + smooth) / (y_true_bg.sum() + y_pred_bg.sum() + smooth)\n",
    "\n",
    "    return dice_bg, dice_fg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "TOA7vlXs5z6k"
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n",
    "    model.train()\n",
    "    scaler = amp.GradScaler()\n",
    "\n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc='Train ')\n",
    "    for step, (images, masks) in pbar:\n",
    "        images = images.to(device, dtype=torch.float)\n",
    "        masks  = masks.to(device, dtype=torch.float)\n",
    "\n",
    "        batch_size = images.size(0)\n",
    "\n",
    "        with amp.autocast(enabled=True):\n",
    "            y_pred = model(images)\n",
    "            loss   = criterion(y_pred, masks)\n",
    "            loss   = loss / CFG.n_accumulate\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if (step + 1) % CFG.n_accumulate == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "\n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "\n",
    "        epoch_loss = running_loss / dataset_size\n",
    "\n",
    "        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        pbar.set_postfix(train_loss=f'{epoch_loss:0.4f}',\n",
    "                        lr=f'{current_lr:0.5f}',\n",
    "                        gpu_mem=f'{mem:0.2f} GB')\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "0egtJc6Y5z6k"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def valid_one_epoch(model, dataloader, device, epoch):\n",
    "    model.eval()\n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    val_scores = []\n",
    "\n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc='Valid ')\n",
    "    for step, (images, masks) in pbar:\n",
    "        images = images.to(device, dtype=torch.float)\n",
    "        masks = masks.to(device, dtype=torch.float)\n",
    "\n",
    "        batch_size = images.size(0)\n",
    "\n",
    "        y_pred = model(images)\n",
    "        loss = criterion(y_pred, masks)\n",
    "\n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        epoch_loss = running_loss / dataset_size\n",
    "\n",
    "        y_pred = torch.sigmoid(y_pred)\n",
    "\n",
    "        # Use your existing dice_per_class function\n",
    "        dice_bg, dice_fg = dice_per_class(masks.to('cpu'), y_pred.to('cpu'))\n",
    "\n",
    "        val_scores.append([dice_bg, dice_fg])\n",
    "\n",
    "        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        pbar.set_postfix(valid_loss=f'{epoch_loss:0.4f}',\n",
    "                         lr=f'{current_lr:0.5f}',\n",
    "                         gpu_memory=f'{mem:0.2f} GB')\n",
    "\n",
    "    val_scores = np.mean(val_scores, axis=0)  # [mean_bg_dice, mean_fg_dice]\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    return epoch_loss, val_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "iJpHE7Ay5z6l"
   },
   "outputs": [],
   "source": [
    "def run_training(model, optimizer, scheduler, device, num_epochs):\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"cuda: {}\\n\".format(torch.cuda.get_device_name()))\n",
    "\n",
    "    start = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_fg_dice   = -np.inf\n",
    "    best_epoch     = -1\n",
    "    history = defaultdict(list)\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        gc.collect()\n",
    "        print(f'Epoch {epoch}/{num_epochs}', end='')\n",
    "\n",
    "        train_loss = train_one_epoch(\n",
    "            model, optimizer, scheduler,\n",
    "            dataloader=train_loader,\n",
    "            device=CFG.device, epoch=epoch\n",
    "        )\n",
    "\n",
    "        val_loss, val_scores = valid_one_epoch(\n",
    "            model, valid_loader,\n",
    "            device=CFG.device,\n",
    "            epoch=epoch\n",
    "        )\n",
    "\n",
    "        val_bg_dice, val_fg_dice = val_scores\n",
    "\n",
    "        history['Train Loss'].append(train_loss)\n",
    "        history['Valid Loss'].append(val_loss)\n",
    "        history['Valid BG Dice'].append(val_bg_dice)\n",
    "        history['Valid FG Dice'].append(val_fg_dice)\n",
    "\n",
    "        # Log metrics\n",
    "        wandb.log({\n",
    "            \"Train Loss\": train_loss,\n",
    "            \"Valid Loss\": val_loss,\n",
    "            \"Valid BG Dice\": val_bg_dice,\n",
    "            \"Valid FG Dice\": val_fg_dice,\n",
    "            \"LR\": scheduler.get_last_lr()[0],\n",
    "        })\n",
    "\n",
    "        print(f' | Valid BG Dice: {val_bg_dice:0.4f} | Valid FG Dice: {val_fg_dice:0.4f}')\n",
    "\n",
    "        # Save best model based on foreground Dice\n",
    "        if val_fg_dice >= best_fg_dice:\n",
    "            print(f\"{c_}Valid FG Dice Improved ({best_fg_dice:0.4f} ---> {val_fg_dice:0.4f})\")\n",
    "            best_fg_dice = val_fg_dice\n",
    "            best_epoch   = epoch\n",
    "            run.summary[\"Best FG Dice\"] = best_fg_dice\n",
    "            run.summary[\"Best Epoch\"]   = best_epoch\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            PATH = f\"best_epoch-{fold:02d}.bin\"\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "            wandb.save(PATH)\n",
    "            print(f\"Model Saved{sr_}\")\n",
    "\n",
    "        # Save last epoch weights\n",
    "        last_model_wts = copy.deepcopy(model.state_dict())\n",
    "        PATH = f\"last_epoch-{fold:02d}.bin\"\n",
    "        torch.save(model.state_dict(), PATH)\n",
    "\n",
    "        print(); print()\n",
    "\n",
    "    end = time.time()\n",
    "    time_elapsed = end - start\n",
    "    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "    print(\"Best FG Dice: {:.4f}\".format(best_fg_dice))\n",
    "\n",
    "    # Load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "CxwJ4Kpn5z6l"
   },
   "outputs": [],
   "source": [
    "def fetch_scheduler(optimizer):\n",
    "    if CFG.scheduler == 'CosineAnnealingLR':\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CFG.T_max,\n",
    "                                                   eta_min=CFG.min_lr)\n",
    "    elif CFG.scheduler == 'CosineAnnealingWarmRestarts':\n",
    "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=CFG.T_0,\n",
    "                                                             eta_min=CFG.min_lr)\n",
    "    elif CFG.scheduler == 'ReduceLROnPlateau':\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                   mode='min',\n",
    "                                                   factor=0.1,\n",
    "                                                   patience=7,\n",
    "                                                   threshold=0.0001,\n",
    "                                                   min_lr=CFG.min_lr,)\n",
    "    elif CFG.scheduer == 'ExponentialLR':\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.85)\n",
    "    elif CFG.scheduler == None:\n",
    "        return None\n",
    "\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xqnlgfsK5z6l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###############\n",
      "### Fold: 0\n",
      "###############\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fold-0|dim-224x224|model-Unet</strong> at: <a href='https://wandb.ai/skj092/ship-detection/runs/e0kol2dc' target=\"_blank\">https://wandb.ai/skj092/ship-detection/runs/e0kol2dc</a><br> View project at: <a href='https://wandb.ai/skj092/ship-detection' target=\"_blank\">https://wandb.ai/skj092/ship-detection</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250710_191135-e0kol2dc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/teamspace/studios/this_studio/wandb/run-20250710_191242-zhabap5y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/skj092/ship-detection/runs/zhabap5y' target=\"_blank\">fold-0|dim-224x224|model-Unet</a></strong> to <a href='https://wandb.ai/skj092/ship-detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/skj092/ship-detection' target=\"_blank\">https://wandb.ai/skj092/ship-detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/skj092/ship-detection/runs/zhabap5y' target=\"_blank\">https://wandb.ai/skj092/ship-detection/runs/zhabap5y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda: Tesla T4\n",
      "\n",
      "Epoch 1/15"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :  95%|█████████▍| 1164/1226 [20:56<01:10,  1.14s/it, gpu_mem=12.72 GB, lr=0.00152, train_loss=0.1620]Premature end of JPEG file\n",
      "Train : 100%|██████████| 1226/1226 [22:05<00:00,  1.08s/it, gpu_mem=12.72 GB, lr=0.00147, train_loss=0.1592]\n",
      "Valid : 100%|██████████| 169/169 [04:28<00:00,  1.59s/it, gpu_memory=7.85 GB, lr=0.00147, valid_loss=0.1151]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | Valid BG Dice: 0.9996 | Valid FG Dice: 0.7768\n",
      "\u001b[32mValid FG Dice Improved (-inf ---> 0.7768)\n",
      "Model Saved\u001b[0m\n",
      "\n",
      "\n",
      "Epoch 2/15"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :   3%|▎         | 33/1226 [00:38<21:18,  1.07s/it, gpu_mem=12.86 GB, lr=0.00145, train_loss=0.1093] "
     ]
    }
   ],
   "source": [
    "for fold in range(1):\n",
    "    print(f'#'*15)\n",
    "    print(f'### Fold: {fold}')\n",
    "    print(f'#'*15)\n",
    "    run = wandb.init(project='ship-detection',\n",
    "                     config={k:v for k, v in dict(vars(CFG)).items() if '__' not in k},\n",
    "                     anonymous=anonymous,\n",
    "                     name=f\"fold-{fold}|dim-{CFG.img_size[0]}x{CFG.img_size[1]}|model-{CFG.model_name}\",\n",
    "                     group=CFG.comment,\n",
    "                    )\n",
    "    train_loader, valid_loader = prepare_loaders(fold=fold, debug=CFG.debug)\n",
    "    model     = build_model()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.wd)\n",
    "    scheduler = fetch_scheduler(optimizer)\n",
    "    model, history = run_training(model, optimizer, scheduler,\n",
    "                                  device=CFG.device,\n",
    "                                  num_epochs=CFG.epochs)\n",
    "    run.finish()\n",
    "    display(ipd.IFrame(run.url, width=1000, height=720))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b9dcABVt5z6m"
   },
   "outputs": [],
   "source": [
    "train_loader, valid_loader = prepare_loaders(fold=fold, debug=CFG.debug)\n",
    "imgs, msks = next(iter(valid_loader))\n",
    "imgs = imgs.to(CFG.device, dtype=torch.float)\n",
    "\n",
    "preds = []\n",
    "for fold in range(1):\n",
    "    model = load_model(f\"best_epoch-{fold:02d}.bin\")\n",
    "    with torch.no_grad():\n",
    "        pred = model(imgs)\n",
    "        pred.squeeze(1)\n",
    "        pred = (nn.Sigmoid()(pred)>0.5).double()\n",
    "    preds.append(pred)\n",
    "\n",
    "imgs  = imgs.cpu().detach()\n",
    "preds = torch.mean(torch.stack(preds, dim=0), dim=0).cpu().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zfBxSzhL5z6m"
   },
   "outputs": [],
   "source": [
    "plot_batch(imgs, msks, size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f-uHuy4-5z6m"
   },
   "outputs": [],
   "source": [
    "plot_batch(imgs, preds.squeeze(1), size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NgPPI2x95z6m"
   },
   "outputs": [],
   "source": [
    "!rm -r ./wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DMUG1G6J5z6m"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "name": "train segmentation shi",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 868324,
     "sourceId": 9988,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "023d9c78749e4e678b34dba3c88f3901": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "TextStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "TextStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "background": null,
      "description_width": "",
      "font_size": null,
      "text_color": null
     }
    },
    "047a2eaba47143e29618de148f11f559": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "18bbc47febfd4d888e55cb3c0d19a048": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "background": null,
      "description_width": "",
      "font_size": null,
      "text_color": null
     }
    },
    "218f95225aeb42c09865a095391746e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "PasswordModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "PasswordModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "PasswordView",
      "continuous_update": true,
      "description": "Token:",
      "description_allow_html": false,
      "disabled": false,
      "layout": "IPY_MODEL_047a2eaba47143e29618de148f11f559",
      "placeholder": "​",
      "style": "IPY_MODEL_023d9c78749e4e678b34dba3c88f3901",
      "tabbable": null,
      "tooltip": null,
      "value": ""
     }
    },
    "30481a4336684a8891e98216fe970655": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": "center",
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": "flex",
      "flex": null,
      "flex_flow": "column",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "50%"
     }
    },
    "4684aab4cf0843dc9dc9664af6c0391e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "background": null,
      "description_width": "",
      "font_size": null,
      "text_color": null
     }
    },
    "491612dc7529421dbb35f1bdea3b3ff0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5006a1a768ef4d21ab853a3dc7ce8df2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Login",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_877bdab0254b498794ddff223faf81f5",
      "style": "IPY_MODEL_9dea999d6ca74fa4b715a6b313006538",
      "tabbable": null,
      "tooltip": null
     }
    },
    "7698104dbbea4c018f90cd2ffb590a6c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "877bdab0254b498794ddff223faf81f5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8f8799948a92487bae776e14065372d0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a95a6b4704a4d65add4065dbdacbb84": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f225b9e9cd064a2596fcdf43466cb18e",
       "IPY_MODEL_aaecf75acb154e25b7a82befa169eb9c",
       "IPY_MODEL_218f95225aeb42c09865a095391746e2",
       "IPY_MODEL_5006a1a768ef4d21ab853a3dc7ce8df2",
       "IPY_MODEL_ee7dd7903cd44480a3d30ba12860ac44"
      ],
      "layout": "IPY_MODEL_30481a4336684a8891e98216fe970655",
      "tabbable": null,
      "tooltip": null
     }
    },
    "9dea999d6ca74fa4b715a6b313006538": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_family": null,
      "font_size": null,
      "font_style": null,
      "font_variant": null,
      "font_weight": null,
      "text_color": null,
      "text_decoration": null
     }
    },
    "aaecf75acb154e25b7a82befa169eb9c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "TextModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "TextModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "TextView",
      "continuous_update": true,
      "description": "Username:",
      "description_allow_html": false,
      "disabled": false,
      "layout": "IPY_MODEL_491612dc7529421dbb35f1bdea3b3ff0",
      "placeholder": "​",
      "style": "IPY_MODEL_ff1fe0a272e54f6c98e66a164d6c9ad7",
      "tabbable": null,
      "tooltip": null,
      "value": ""
     }
    },
    "ee7dd7903cd44480a3d30ba12860ac44": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_allow_html": false,
      "layout": "IPY_MODEL_7698104dbbea4c018f90cd2ffb590a6c",
      "placeholder": "​",
      "style": "IPY_MODEL_4684aab4cf0843dc9dc9664af6c0391e",
      "tabbable": null,
      "tooltip": null,
      "value": "\n<b>Thank You</b></center>"
     }
    },
    "f225b9e9cd064a2596fcdf43466cb18e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_allow_html": false,
      "layout": "IPY_MODEL_8f8799948a92487bae776e14065372d0",
      "placeholder": "​",
      "style": "IPY_MODEL_18bbc47febfd4d888e55cb3c0d19a048",
      "tabbable": null,
      "tooltip": null,
      "value": "<center> <img\nsrc=https://www.kaggle.com/static/images/site-logo.png\nalt='Kaggle'> <br> Create an API token from <a\nhref=\"https://www.kaggle.com/settings/account\" target=\"_blank\">your Kaggle\nsettings page</a> and paste it below along with your Kaggle username. <br> </center>"
     }
    },
    "ff1fe0a272e54f6c98e66a164d6c9ad7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "TextStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "TextStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "background": null,
      "description_width": "",
      "font_size": null,
      "text_color": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
